{% extends "base.html" %}

{% block head %}
    <style>
        .note-card { transition: all 0.3s ease; }
        .note-card:hover { transform: translateY(-2px); box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1); }
        .pulse { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
    </style>
{% endblock %}

{% block content %}
    <div class="max-w-4xl mx-auto">
        <!-- Voice Recording Interface -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-8">
            <h2 class="text-2xl font-bold mb-4 text-gray-800">Record Your Note</h2>
            <div class="flex flex-col items-center space-y-4">
                <div id="status" class="text-gray-600 mb-4">Click the microphone to start recording</div>
                <button id="recordButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-full focus:outline-none">
                    <i class="fas fa-microphone text-xl"></i>
                </button>
                <div id="recordingIndicator" class="hidden items-center text-red-500">
                    <div class="w-3 h-3 bg-red-500 rounded-full mr-2 pulse"></div>
                    <span>Recording...</span>
                </div>
                <div class="w-full mt-4">
                    <label for="noteContent" class="block text-gray-700 text-sm font-bold mb-2">
                        Or type your note here:
                    </label>
                    <textarea id="noteContent" rows="4" 
                        class="w-full px-3 py-2 text-gray-700 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
                        placeholder="Type your note here or use the microphone to record..."></textarea>
                    <button id="saveNoteBtn" 
                        class="mt-2 bg-green-500 hover:bg-green-600 text-white font-bold py-2 px-4 rounded">
                        Save Note
                    </button>
                </div>
            </div>
        </div>

        <!-- Notes List -->
        <div id="notesContainer">
            <h2 class="text-2xl font-bold mb-4 text-gray-800">Your Notes</h2>
            <div id="notesList" class="grid gap-4 md:grid-cols-2 lg:grid-cols-3">
                {% for note in notes %}
                <div class="note-card bg-white rounded-lg shadow-md p-4">
                    <div class="flex justify-between items-start">
                        <p class="text-gray-700 mb-2 flex-grow">{{ note.content }}</p>
                        <button onclick="deleteNote({{ note.id }})"class="text-red-500 hover:text-red-700 ml-2">
                            <i class="fas fa-trash"></i>
                        </button>
                    </div>
                    <div class="text-xs text-gray-500 mt-2">
                        {{ note.created_at.strftime('%b %d, %Y %I:%M %p') }}
                    </div>
                </div>
                {% else %}
                <div class="col-span-3 text-center py-8 text-gray-500">
                    <p>No notes yet. Record your first note using the microphone above!</p>
                </div>
                {% endfor %}
            </div>
        </div>
    </div>
{% endblock %}

{% block scripts %}
<script>
    let mediaRecorder, audioChunks = [];
    const recordButton = document.getElementById('recordButton');
    const recordingIndicator = document.getElementById('recordingIndicator');
    const statusElement = document.getElementById('status');
    const noteContent = document.getElementById('noteContent');
    const saveNoteBtn = document.getElementById('saveNoteBtn');

    if (!navigator.mediaDevices || !window.MediaRecorder) {
        statusElement.textContent = 'Your browser does not support audio recording.';
        recordButton.disabled = true;
    }

    recordButton.addEventListener('click', toggleRecording);
    saveNoteBtn.addEventListener('click', saveNote);

    async function toggleRecording() {
        if (mediaRecorder?.state === 'recording') {
            mediaRecorder.stop();
            recordButton.innerHTML = '<i class="fas fa-microphone text-xl"></i>';
            recordButton.className = recordButton.className.replace('bg-red-600', 'bg-blue-600').replace('hover:bg-red-700', 'hover:bg-blue-700');
            recordingIndicator.classList.add('hidden');
            statusElement.textContent = 'Processing your speech...';
        } else {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        sampleSize: 16,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                audioChunks = [];
                const options = { 
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 128000,
                    bitsPerSecond: 128000
                };
                mediaRecorder = new MediaRecorder(stream, options);
                
                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) {
                        audioChunks.push(e.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudioToServer(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start(100); // Collect data every 100ms
                recordButton.innerHTML = '<i class="fas fa-stop text-xl"></i>';
                recordButton.className = recordButton.className.replace('bg-blue-600', 'bg-red-600').replace('hover:bg-blue-700', 'hover:bg-red-700');
                recordingIndicator.classList.remove('hidden');
                statusElement.textContent = 'Recording... Click to stop';
            } catch (error) {
                console.error('Error:', error);
                statusElement.textContent = 'Error accessing microphone: ' + error.message;
            }
        }
    }

    async function convertWebmToWav(webmBlob) {
        return new Promise((resolve) => {
            // Create an audio context
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            // Create a file reader to read the WebM blob
            const fileReader = new FileReader();
            
            fileReader.onload = async function(e) {
                try {
                    // Decode the WebM audio data
                    const audioData = await audioContext.decodeAudioData(e.target.result);
                    
                    // Create an offline audio context with the same parameters
                    const offlineCtx = new OfflineAudioContext(
                        audioData.numberOfChannels,
                        audioData.length,
                        audioData.sampleRate
                    );
                    
                    // Create a buffer source
                    const source = offlineCtx.createBufferSource();
                    source.buffer = audioData;
                    
                    // Connect to destination
                    source.connect(offlineCtx.destination);
                    
                    // Start rendering
                    source.start(0);
                    
                    // Render the audio to a new buffer
                    const renderedBuffer = await offlineCtx.startRendering();
                    
                    // Convert to WAV format
                    const wavBlob = bufferToWave(renderedBuffer, renderedBuffer.length);
                    
                    resolve(wavBlob);
                } catch (error) {
                    console.error('Error converting WebM to WAV:', error);
                    // Fallback to the original blob if conversion fails
                    resolve(webmBlob);
                }
            };
            
            fileReader.readAsArrayBuffer(webmBlob);
        });
    }
    
    // Helper function to convert AudioBuffer to WAV Blob
    function bufferToWave(abuffer, len) {
        const numOfChan = abuffer.numberOfChannels;
        const length = len * numOfChan * 2 + 44;
        const buffer = new ArrayBuffer(length);
        const view = new DataView(buffer);
        let offset = 0;
        
        // Write WAV header
        writeString(view, offset, 'RIFF'); offset += 4; // RIFF header
        view.setUint32(offset, length - 8, true); offset += 4; // file length
        writeString(view, offset, 'WAVE'); offset += 4; // WAVE header
        writeString(view, offset, 'fmt '); offset += 4; // format chunk identifier
        view.setUint32(offset, 16, true); offset += 4; // format chunk length
        view.setUint16(offset, 1, true); offset += 2; // audio format (1 = PCM)
        view.setUint16(offset, numOfChan, true); offset += 2; // channels
        view.setUint32(offset, abuffer.sampleRate, true); offset += 4; // sample rate
        view.setUint32(offset, abuffer.sampleRate * 2 * numOfChan, true); offset += 4; // byte rate
        view.setUint16(offset, numOfChan * 2, true); offset += 2; // block align
        view.setUint16(offset, 16, true); offset += 2; // bits per sample
        writeString(view, offset, 'data'); offset += 4; // data chunk identifier
        view.setUint32(offset, length - 44, true); offset += 4; // data chunk length
        
        // Write PCM audio data
        const channels = [];
        for (let i = 0; i < abuffer.numberOfChannels; i++) {
            channels.push(abuffer.getChannelData(i));
        }
        
        for (let i = 0; i < abuffer.length; i++) {
            for (let channel = 0; channel < abuffer.numberOfChannels; channel++) {
                const sample = Math.max(-1, Math.min(1, channels[channel][i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }
        }
        
        return new Blob([view], { type: 'audio/wav' });
    }
    
    // Helper function to write string to DataView
    function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }

    async function sendAudioToServer(audioBlob) {
        try {
            statusElement.textContent = 'Processing audio...';
            
            // Convert WebM to WAV
            const wavBlob = await convertWebmToWav(audioBlob);
            
            const formData = new FormData();
            formData.append('audio', wavBlob, 'recording.wav');
            
            statusElement.textContent = 'Sending audio for transcription...';
            const response = await fetch('/transcribe', {
                method: 'POST',
                body: formData,
                headers: {
                    'Accept': 'application/json'
                }
            });
            
            // First check if the response is JSON
            const contentType = response.headers.get('content-type');
            if (!contentType || !contentType.includes('application/json')) {
                const text = await response.text();
                console.error('Non-JSON response:', text);
                throw new Error(`Server returned ${response.status}: ${response.statusText}`);
            }
            
            const data = await response.json();
            if (!response.ok) {
                throw new Error(data.error || `Server error: ${response.status} ${response.statusText}`);
            }
            
            if (data.text) {
                noteContent.value = data.text;
                statusElement.textContent = 'Transcription complete! Click save to keep this note.';
            } else {
                throw new Error('No text was transcribed');
            }
        } catch (error) {
            console.error('Error details:', error);
            statusElement.textContent = 'Error: ' + (error.message || 'Failed to process audio. Please check console for details.');
        }
    }

    async function saveNote() {
        const content = noteContent.value.trim();
        if (!content) {
            statusElement.textContent = 'Please record or type a note before saving.';
            return;
        }

        try {
            const response = await fetch('/save_note', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ content })
            });

            const data = await response.json();
            if (data.success) {
                const notesList = document.getElementById('notesList');
                const noteHtml = `
                    <div class="note-card bg-white rounded-lg shadow-md p-4">
                        <div class="flex justify-between items-start">
                            <p class="text-gray-700 mb-2 flex-grow">${content}</p>
                            <button onclick="deleteNote(${data.id})" class="text-red-500 hover:text-red-700 ml-2">
                                <i class="fas fa-trash"></i>
                            </button>
                        </div>
                        <div class="text-xs text-gray-500 mt-2">Just now</div>
                    </div>`;
                
                if (notesList.children.length === 1 && notesList.children[0].classList.contains('col-span-3')) {
                    notesList.innerHTML = noteHtml;
                } else {
                    notesList.insertAdjacentHTML('afterbegin', noteHtml);
                }
                
                noteContent.value = '';
                statusElement.textContent = 'Note saved successfully!';
            }
        } catch (error) {
            console.error('Error:', error);
            statusElement.textContent = 'Error saving note: ' + error.message;
        }
    }

    async function deleteNote(noteId) {
        if (!confirm('Are you sure you want to delete this note?')) return;
        
        try {
            const response = await fetch(`/delete_note/${noteId}`, { method: 'DELETE' });
            const data = await response.json();
            if (data.success) {
                const noteElement = document.querySelector(`button[onclick="deleteNote(${noteId})"]`).closest('.note-card');
                noteElement.remove();
                
                const notesList = document.getElementById('notesList');
                if (notesList.children.length === 0) {
                    notesList.innerHTML = `
                        <div class="col-span-3 text-center py-8 text-gray-500">
                            <p>No notes yet. Record your first note using the microphone above!</p>
                        </div>`;
                }
            }
        } catch (error) {
            console.error('Error:', error);
            alert('Error deleting note: ' + error.message);
        }
    }
</script>
{% endblock %}
